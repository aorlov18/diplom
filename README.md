1. Используется:
- Ubuntu server
- Gitlab, gitlab-runner
- Docker Hub

2. Для работы terraform создать файл variables.tf с указанием переменных данных для подключения к облаку (cloud_id, folder_id, zone). Если доступ к облаку организован через сервисный аккаунт, то необходимо создать файл key.json с указанием данных сервисного аккаунта. Вариант использования token: закоментировать в main.tf service_account_key_file ... и раскоментировать token, данные token внести в файл variable.tf.

3. Как терраформ завершит создание серверов, актуализировать значения ip адресов в файле ansible/inventory.yml 

4. перееходим в папку ансибль и запускаем ansible-playbook play.yml

5. по заверешению работы ансибль, заходим на сервер srv под именем user

6. git clone git@gitlab.com:devops5483744/django.git
docker push alexorl/mydjango:tagname
https://hub.docker.com/r/alexorl/mydjango

7. запускаем 
gitlab-runner register
на вопрос Enter an executor: выбираем docker

gitlab-runner run

8. В настройках CI/CD Gitlab добавляем две переменные - DOCKER_USERNAME и DOCKER_PASSWORD. Соответственно, логин и пароль для прохождения валидации в репозитории Docker Hub.

9. Для корректной работы kubectl на srv берем содержимое файла /etc/kubernetes/admin.conf с мастера kubernetes и копируем его в такой же файл на srv.


8.



Структура проекта

В процессе выполнения проекта необходимо будет описать в Git:

        конфигурации серверов в облачной инфраструктуре (IaC);
        пайплайны для сборки и деплоя исходного приложения.
        конфигурации мониторинга и сборку логов этого приложения.

Задача
Опишите инфраструктуру будущего проекта в виде кода с инструкциями по развертке, нужен кластер Kubernetes и служебный сервер (будем называть его srv).

1.Выбираем облачный провайдер и инфраструктуру.
  В качестве облака подойдет и Яндекс.Облако, 
Нам нужно три сервера:
        два сервера в одном кластере Kubernetes: 1 master и 1 app;
        сервер srv для инструментов мониторинга, логгирования и сборок контейнеров

2 Описываем инфраструктуру.
  Описывать инфраструктуру мы будем, конечно, в Terraform.

     Совет: лучше создать под наши конфигурации отдельную группу проектов в Git, например, devops.
   Пишем в README.md инструкцию по развертке конфигураций в облаке. Никаких секретов в коде быть не должно.

3. Автоматизируем установку.
    Надо реализовать возможность установки на сервер всех необходимых нам настроек и пакетов, будь то docker-compose, gitlab-runner или наши публичные ключи для доступа по SSH. Положите код автоматизации в Git-репозиторий.

    Результат должен быть такой, чтобы после запуска подобной автоматизации на сервере устанавливалось почти всё, что нужно.
   Совсем полностью исключать ручные действия не надо, но в таком случае их надо описать в том же README.md и положить в репозиторий.
Совет: лучше использовать для этого Ansible.
_____________
1.Клонируем репозиторий, собираем его на сервере srv.

  Исходники простого приложения можно взять здесь(https://github.com/vinhlee95/django-pg-docker-tutorial). Это простое приложение на Django с уже написанным Dockerfile. Приложение работает с PostgreSQL, в самом репозитории уже есть реализация docker-compose — её можно брать за референс при написании Helm-чарта.

  Необходимо склонировать репозиторий выше к себе в Git и настроить пайплайн с этапом сборки образа и отправки его в любой docker registry. Для пайплайнов можно использовать GitLab, Jenkins или GitHub Actions — кому что нравится. Рекомендуем GitLab.

2. Описываем приложение в Helm-чарт.

Описываем приложение в виде конфигов в Helm-чарте. По сути, там только два контейнера — с базой и приложением, так что ничего сложного в этом нет. Стоит хранить данные в БД с помощью PVC в Kubernetes.

3. Описываем стадию деплоя в Helm.

  Настраиваем деплой стадию пайплайна. Применяем Helm-чарт в наш кластер. Нужно сделать так, чтобы наше приложение разворачивалось после сборки в Kubernetes и было доступно по бесплатному домену или на IP-адресе с выбранным портом.

  Для деплоя должен использоваться свежесобранный образ. По возможности нужно реализовать сборку из тегов в Git, где тег репозитория в Git будет равен тегу собираемого образа.
______
1. Настройка сборки логов.
Выберите инструмент, с помощью которого такой функционал можно предоставить. Нужно собирать логи работы пода приложения. Хранить это всё можно либо в самом кластере Kubernetes, либо на srv-сервере.

2. Выбор метрик для мониторинга.

Так, теперь творческий этап. Допустим, наше приложение имеет для нас некоторую важность. Мы бы хотели знать, когда пользователь не может на него попасть — время отклика, сертификат, статус код и так далее. Выберите метрики и инструмент, с помощью которого будем отслеживать его состояние.
  Важно! Весь мониторинг должен находиться на srv-сервере, чтобы в случае падения кластера мы все равно могли узнать об этом.

3. Настройка дашборда.

  Ко всему прочему хотелось бы и наблюдать за метриками в разрезе времени. Для этого мы можем использовать Grafana и Zabbix — что больше понравилось.

4. Алертинг.

А теперь добавим уведомления в наш любимый мессенджер, точнее в ваш любимый мессенджер. Обязательно протестируйте отправку уведомлений. Попробуйте «убить» приложение самостоятельно, и засеките время от инцидента до получения уведомления. Если время адекватное, то можно считать, что вы справились с этим проектом!

_______
Задача: 
3 сервера: srv - отдельно для мониторинга, логирования и сборок контейнеров
, master и app - в 1м кластере

srv:
клонируем репозиторий https://github.com/vinhlee95/django-pg-docker-tutorial
сборка контейнеров по тегу, пулим в docker-registry
тег репозитория в git будет равен тегу собираемого образа, типа  hub.docker.com/skillfactory/testapp:2.0.3 - запускается

деплой через helm разворачиваем после сборки в кубере наше приложение. хранение баз с помощью PVC в Kubernetes.
